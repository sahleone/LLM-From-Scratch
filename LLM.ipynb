{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LLM From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is adapted from a freeCodeCamp YouTube tutorial, which you can watch [here](https://www.youtube.com/watch?v=UU1WVnMk4E8). Note that this version is not identical to the [code](https://github.com/Infatoshi/fcc-intro-to-llms) provided in the tutorial. I have made some changes just because. also working on a mac\n",
    "\n",
    "needed to remove the prefix and suffix from The Project Gutenberg in the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rhysjervis/Documents/GitHub/LLM-From-Scratch/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional  as F\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Var/hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['block_size'] = 64\n",
    "config['batch_size'] = 32\n",
    "config['epoch'] = 10000\n",
    "config['learning_rate'] = 5e-5 #3e-3, 3e-4, 1e-3,1e-4\n",
    "config['eval_iters'] = 250\n",
    "config['n_embd'] = 128\n",
    "config['n_head'] = 2\n",
    "config['n_layer'] = 4\n",
    "config['dropout'] = 0.2\n",
    "config['device'] = torch.device('cpu') # set as default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Set device based on availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA (GPU)\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')  # Assuming first GPU if MPS is available\n",
    "    print(\"Using MPS\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(\"Device:\", device)\n",
    "\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '\"', '$', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '£', '°', '´', '·', 'À', 'Á', 'Æ', 'Ç', 'É', 'à', 'á', 'â', 'ä', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'î', 'ï', 'ó', 'ô', 'ö', 'ú', 'û', 'ü', 'ý', 'Œ', 'œ', 'Φ', 'α', 'η', 'λ', 'μ', 'ν', 'ξ', 'ο', 'ρ', 'ς', 'τ', 'ϰ', 'ו', 'ח', 'ὁ', 'ὑ', '—', '‘', '’', '“', '”', '…', '─', '❧', '\\ufeff']\n",
      "length of text: 11770361\n",
      "Set of characters: 140\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty string to hold all the text\n",
    "all_text = \"\"\n",
    "\n",
    "# Path to the directory containing the book files\n",
    "books_dir = 'books'\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(books_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(books_dir, filename), 'r', encoding='utf-8') as f:\n",
    "            # Read the content of the file and append it to all_text\n",
    "            all_text += f.read() + \" \"  # Add a \n",
    "    \n",
    "vocab = sorted(set(all_text))\n",
    "config['vocab_size'] = len(vocab)\n",
    "print(vocab)\n",
    "print(\"length of text:\",len(all_text))\n",
    "print(f\"Set of characters: {config['vocab_size']}\")\n",
    "#print(\"First Fifty Characters:\\n\", text[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = {ch:i for i,ch in enumerate(vocab)}\n",
    "int_to_string = {i:ch for i,ch in enumerate(vocab)}\n",
    "\n",
    "def encoder(string:str):\n",
    "    \n",
    "    return [string_to_int[ch] for ch in string]\n",
    "\n",
    "def decoder(vector):\n",
    "    \n",
    "    return \" \".join([int_to_string[i] for i in vector])\n",
    "    \n",
    "    \n",
    "data = torch.tensor(encoder(all_text),dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "tensor([[61, 66, 63,  ..., 76, 69, 66],\n",
      "        [71, 61,  2,  ...,  2, 76, 73],\n",
      "        [76, 77, 58,  ..., 63, 66, 75],\n",
      "        ...,\n",
      "        [62, 75, 76,  ..., 77, 65, 66],\n",
      "        [76, 77,  2,  ..., 78, 75, 79],\n",
      "        [60, 65, 66,  ..., 58, 66, 71]], device='mps:0')\n",
      "Targets:\n",
      "tensor([[66, 63, 63,  ..., 69, 66, 73],\n",
      "        [61,  2, 64,  ..., 76, 73, 62],\n",
      "        [77, 58, 71,  ..., 66, 75, 76],\n",
      "        ...,\n",
      "        [75, 76, 11,  ..., 65, 66, 76],\n",
      "        [77,  2, 72,  ..., 75, 79, 82],\n",
      "        [65, 66, 72,  ..., 66, 71, 76]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    \"\"\"\n",
    "    Function to generate a batch of data.\n",
    "    \n",
    "    Parameters:\n",
    "    - split (str): 'train' or 'val' to specify which dataset to use.\n",
    "    \n",
    "    Returns:\n",
    "    - x (Tensor): Input tensor of shape (batch_size, block_size).\n",
    "    - y (Tensor): Target tensor of shape (batch_size, block_size).\n",
    "    \"\"\"\n",
    "    # Select the appropriate dataset based on the split\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Randomly choose starting indices for the batch\n",
    "    ix = torch.randint(len(data) - config['block_size'], (config['batch_size'],))\n",
    "    \n",
    "    # Generate the input (x) and target (y) tensors\n",
    "    x = torch.stack([data[i:i + config['block_size']] for i in ix])\n",
    "    y = torch.stack([data[i + 1:i + config['block_size'] + 1] for i in ix])\n",
    "    \n",
    "    # Move the tensors to the specified device (CPU, CUDA, or MPS)\n",
    "    x, y = x.to(config['device']), y.to(config['device'])\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "# Example usage: Get a batch from the training data\n",
    "x, y = get_batch('train')\n",
    "\n",
    "# Display the input and target tensors\n",
    "print('Inputs:')\n",
    "print(x)\n",
    "print('Targets:')\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, _ = self(index)  # Call model directly instead of forward\n",
    "            logits = logits[:, -1, :]  # Focus on the last time step\n",
    "            probs = F.softmax(logits, dim=-1)  # Get probabilities\n",
    "            index_next = torch.multinomial(probs, num_samples=1)  # Sample from distribution\n",
    "            index = torch.cat((index, index_next), dim=1)  # Append sampled index\n",
    "        return index\n",
    "\n",
    "model = BigramLanguageModel(config['vocab_size'])\n",
    "m = model.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(config['eval_iters'])\n",
    "        for k in range(config['eval_iters']):\n",
    "            X, Y = get_batch(split)\n",
    "            _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after last time the validation loss improved.\n",
    "                            Default: 5\n",
    "            min_delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                               Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 5.229, val loss: 5.232\n",
      "step: 250, train loss: 5.212, val loss: 5.209\n",
      "step: 500, train loss: 5.190, val loss: 5.191\n",
      "step: 750, train loss: 5.169, val loss: 5.173\n",
      "step: 1000, train loss: 5.149, val loss: 5.155\n",
      "step: 1250, train loss: 5.132, val loss: 5.132\n",
      "step: 1500, train loss: 5.115, val loss: 5.113\n",
      "step: 1750, train loss: 5.091, val loss: 5.094\n",
      "step: 2000, train loss: 5.074, val loss: 5.078\n",
      "step: 2250, train loss: 5.055, val loss: 5.058\n",
      "step: 2500, train loss: 5.035, val loss: 5.042\n",
      "step: 2750, train loss: 5.018, val loss: 5.020\n",
      "step: 3000, train loss: 4.999, val loss: 5.003\n",
      "step: 3250, train loss: 4.980, val loss: 4.983\n",
      "step: 3500, train loss: 4.959, val loss: 4.964\n",
      "step: 3750, train loss: 4.941, val loss: 4.945\n",
      "step: 4000, train loss: 4.924, val loss: 4.927\n",
      "step: 4250, train loss: 4.907, val loss: 4.910\n",
      "step: 4500, train loss: 4.888, val loss: 4.892\n",
      "step: 4750, train loss: 4.867, val loss: 4.869\n",
      "step: 5000, train loss: 4.850, val loss: 4.856\n",
      "step: 5250, train loss: 4.833, val loss: 4.835\n",
      "step: 5500, train loss: 4.814, val loss: 4.817\n",
      "step: 5750, train loss: 4.795, val loss: 4.798\n",
      "step: 6000, train loss: 4.777, val loss: 4.783\n",
      "step: 6250, train loss: 4.760, val loss: 4.761\n",
      "step: 6500, train loss: 4.741, val loss: 4.745\n",
      "step: 6750, train loss: 4.727, val loss: 4.728\n",
      "step: 7000, train loss: 4.704, val loss: 4.710\n",
      "step: 7250, train loss: 4.686, val loss: 4.693\n",
      "step: 7500, train loss: 4.671, val loss: 4.676\n",
      "step: 7750, train loss: 4.654, val loss: 4.658\n",
      "step: 8000, train loss: 4.635, val loss: 4.642\n",
      "step: 8250, train loss: 4.620, val loss: 4.624\n",
      "step: 8500, train loss: 4.601, val loss: 4.605\n",
      "step: 8750, train loss: 4.582, val loss: 4.587\n",
      "step: 9000, train loss: 4.567, val loss: 4.571\n",
      "step: 9250, train loss: 4.548, val loss: 4.554\n",
      "step: 9500, train loss: 4.532, val loss: 4.540\n",
      "step: 9750, train loss: 4.514, val loss: 4.521\n",
      "Final loss: 4.482\n"
     ]
    }
   ],
   "source": [
    "# Initialize the early stopping object\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.001)\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "# Initialize lists to store the losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iter in range(config['epoch']):\n",
    "    if iter % config['eval_iters'] == 0:\n",
    "        losses = estimate_loss()\n",
    "        train_losses.append(losses['train'])\n",
    "        val_losses.append(losses['val'])\n",
    "\n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "\n",
    "       # Check for early stopping\n",
    "        early_stopping(losses['val'])\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Print the final loss value\n",
    "print(f\"Final loss: {loss.item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Evaluation Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" \n",
    "    One head of self-attention mechanism.\n",
    "\n",
    "    This class implements a single self-attention head,\n",
    "    which is a component of the multi-head self-attention mechanism in transformer models.\n",
    "    The self-attention mechanism allows the model to focus on different parts of the input sequence\n",
    "    when making predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        \"\"\"\n",
    "        Initializes the Head instance.\n",
    "\n",
    "        Args:\n",
    "            head_size (int): The size of the attention head,\n",
    "            which is the dimensionality of the key, query, and value vectors.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(config['n_embd'], head_size, bias=False)\n",
    "        self.query = nn.Linear(config['n_embd'], head_size, bias=False)\n",
    "        self.value = nn.Linear(config['n_embd'], head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(config['block_size'], config['block_size'])))\n",
    "\n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the self-attention head.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, time_steps, channels).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch_size, time_steps, head_size), \n",
    "            which is the result of applying the self-attention mechanism to the input.\n",
    "        \"\"\"\n",
    "\n",
    "        # Unpack the dimensions of the input tensor\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        # Transform the input into key, query, and value vectors\n",
    "        k = self.key(x)   # (B, T, head_size)\n",
    "        q = self.query(x) # (B, T, head_size)\n",
    "\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "\n",
    "        # Apply masking to prevent attending to future positions\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "\n",
    "        # Normalize the attention scores using softmax\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "\n",
    "        # Apply dropout for regularization\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" \n",
    "    Multiple heads of self-attention in parallel.\n",
    "\n",
    "    This class implements the multi-head attention mechanism,\n",
    "      which allows the model to focus on different parts of the input sequence in parallel.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        \"\"\"\n",
    "        Initializes the MultiHeadAttention instance.\n",
    "\n",
    "        Args:\n",
    "            num_heads (int): The number of attention heads.\n",
    "            head_size (int): The size of each attention head.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, config['n_embd'])\n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the multi-head attention mechanism.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, time_steps, channels).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch_size, time_steps, config['n_embd']),\n",
    "            which is the result of applying the multi-head attention mechanism to the input.\n",
    "        \"\"\"\n",
    "\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" \n",
    "    A simple feedforward neural network with non-linearity and dropout.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        \"\"\"\n",
    "        Initializes the FeedForward module.\n",
    "\n",
    "        Args:\n",
    "            n_embd (int): The dimensionality of the input embeddings.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(config['dropout']),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the feedforward network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, sequence_length, n_embd).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of the same shape as the input, \n",
    "            but processed by the feedforward network.\n",
    "        \"\"\"\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\" \n",
    "    A Transformer block consisting of multi-head self-attention and a feedforward network.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        \"\"\"\n",
    "        Initializes the Transformer Block.\n",
    "\n",
    "        Args:\n",
    "            n_embd (int): The dimensionality of the input embeddings.\n",
    "            n_head (int): The number of attention heads.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the Transformer block.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, sequence_length, n_embd).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of the same shape as the input, \n",
    "            processed by the multi-head self-attention and feedforward network.\n",
    "        \"\"\"\n",
    "        # Multi-head self-attention followed by residual connection and layer normalization\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "\n",
    "        # Feedforward network followed by residual connection and layer normalization\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class GPTLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A Generative Pre-trained Transformer (GPT) language model.\n",
    "    \n",
    "    This model generates text by predicting the next token in a sequence based on previous tokens.\n",
    "    It is composed of token and positional embeddings, multiple transformer blocks, \n",
    "    and a final linear layer to output logits for each token in the vocabulary.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size):\n",
    "        \"\"\"\n",
    "        Initializes the GPT language model.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): The size of the vocabulary (i.e., the number of unique tokens).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, config['n_embd'])\n",
    "        self.position_embedding_table = nn.Embedding(config['block_size'], config['n_embd'])\n",
    "        self.blocks = nn.Sequential(*[Block(config['n_embd'], n_head=config['n_head']) for _ in range(config['n_layer'])])\n",
    "        self.ln_f = nn.LayerNorm(config['n_embd']) # final layer norm\n",
    "        self.lm_head = nn.Linear(config['n_embd'], vocab_size)\n",
    "        \n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"\n",
    "        Initializes the weights of the model's layers.\n",
    "\n",
    "        Args:\n",
    "            module (nn.Module): A module from the model, either Linear or Embedding.\n",
    "        \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the GPT model.\n",
    "\n",
    "        Args:\n",
    "            index (torch.Tensor): Input tensor of shape (batch_size, sequence_length) with token indices.\n",
    "            targets (torch.Tensor, optional): Target tensor of shape (batch_size, sequence_length) for calculating loss.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - logits (torch.Tensor): Output logits of shape (batch_size, sequence_length, vocab_size).\n",
    "                - loss (torch.Tensor or None): The cross-entropy loss if targets are provided, otherwise None.\n",
    "        \"\"\"\n",
    "\n",
    "        B, T = index.shape\n",
    "        \n",
    "    \n",
    "        # Get token and position embeddings\n",
    "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        \n",
    "        # Combine token and position embeddings\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        \n",
    "        # Pass through transformer blocks\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        \n",
    "        # Final layer normalization\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        \n",
    "        # Output logits for each token in the vocabulary\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        \n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        \"\"\"\n",
    "        Generates a sequence of tokens using the model.\n",
    "\n",
    "        Args:\n",
    "            index (torch.Tensor): Input tensor of shape (batch_size, sequence_length) with token indices.\n",
    "            max_new_tokens (int): The maximum number of new tokens to generate.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: A tensor of shape (batch_size, sequence_length + max_new_tokens) with the generated token indices.\n",
    "        \"\"\"\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Crop the input sequence to the last 'block_size' tokens. \n",
    "            # This ensures that the model considers only the most recent tokens in the sequence, \n",
    "            # which are the most relevant for predicting the next token. \n",
    "            # This also helps in maintaining computational efficiency by not exceeding the model's designed capacity \n",
    "            # for handling context, which is limited by 'block_size'.\n",
    "            index_cond = index[:, -config['block_size']:]\n",
    "\n",
    "            # Get predictions for the next token\n",
    "            logits, loss = self.forward(index_cond)\n",
    "\n",
    "            # Focus only on the last time step's logits\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "\n",
    "            # Sample the next token from the probability distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "\n",
    "            # Append the sampled token to the current sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rhysjervis/Documents/GitHub/LLM-From-Scratch/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 8013/8013 [00:19<00:00, 410.19 examples/s]\n",
      "/Users/rhysjervis/Documents/GitHub/LLM-From-Scratch/.venv/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 201/201 [00:16<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Average Loss: 10.06820160120874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:17<02:33, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after Epoch 0: 9.324832145984356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:15<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 8.700730461386305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:32<02:10, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after Epoch 1: 8.210807690253624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:15<00:00, 13.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 7.690792377908432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:48<01:52, 16.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after Epoch 2: 7.3256521958571215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:15<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 6.863313632224923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:04<01:35, 15.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after Epoch 3: 6.587827260677631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:15<00:00, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 6.181699038738042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:20<01:19, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after Epoch 4: 5.98881090604342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:15<00:00, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 5.641061464945476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:36<01:03, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after Epoch 5: 5.5278592843275804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:15<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 5.238367785268755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:52<00:47, 15.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after Epoch 6: 5.196414085534903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:15<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 4.957848110009189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:08<00:31, 15.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after Epoch 7: 4.977399550951445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:15<00:00, 13.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 4.784177934352439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [02:23<00:15, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after Epoch 8: 4.853499229137714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:15<00:00, 13.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 4.699794577128851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:39<00:00, 15.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after Epoch 9: 4.813225177618174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.79058023599478\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"openwebtext\")\n",
    "\n",
    "# Select a portion of the dataset (e.g., 1% of the data)\n",
    "subset_size = 0.001  # Define the subset size as 1% of the dataset\n",
    "num_samples = int(len(dataset['train']) * subset_size)  # Calculate the number of samples to select\n",
    "dataset = dataset['train'].shuffle(seed=42).select(range(num_samples))  # Shuffle and select the subset\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')  # Load the GPT-2 tokenizer\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Add a padding token to the tokenizer\n",
    "\n",
    "config['vocab_size'] = len(tokenizer)\n",
    "config['epoch'] = 10\n",
    "# Define a function to tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'], \n",
    "        padding='max_length',  # Pad sequences to the maximum length\n",
    "        truncation=True,  # Truncate sequences that exceed the maximum length\n",
    "        max_length=config['block_size']  # Set the maximum sequence length (block size)\n",
    "    )\n",
    "\n",
    "# Apply the tokenization function to the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])  # Tokenize the dataset and remove the original text column\n",
    "\n",
    "# Convert tokenized datasets to DataFrame\n",
    "train_df = pd.DataFrame(tokenized_datasets)  # Convert the tokenized dataset to a DataFrame\n",
    "\n",
    "# Split the dataset into training and validation + test sets\n",
    "train_df, val_test_df = train_test_split(train_df, test_size=0.2, random_state=42)  # Split the dataset: 80% training, 20% validation + test\n",
    "\n",
    "# Split the remaining dataset into validation and test sets\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42)  # Split the validation + test set equally into validation and test sets\n",
    "\n",
    "# Convert DataFrames back to Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)  # Convert the training DataFrame back to a Dataset\n",
    "val_dataset = Dataset.from_pandas(val_df)  # Convert the validation DataFrame back to a Dataset\n",
    "test_dataset = Dataset.from_pandas(test_df)  # Convert the test DataFrame back to a Dataset\n",
    "\n",
    "# Define a collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'input_ids': torch.tensor([item['input_ids'] for item in batch], device=config['device']),  # Convert input_ids to a tensor and move to device\n",
    "        'attention_mask': torch.tensor([item['attention_mask'] for item in batch], device=config['device']),  # Convert attention_mask to a tensor and move to device\n",
    "        'labels': torch.tensor([item['input_ids'] for item in batch], device=config['device'])  # Use input_ids as labels (for GPT models)\n",
    "    }\n",
    "\n",
    "# Create DataLoaders for training, validation, and testing\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, collate_fn=collate_fn)  # DataLoader for training\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=collate_fn)  # DataLoader for validation\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=collate_fn)  # DataLoader for testing\n",
    "\n",
    "# Initialize the model\n",
    "model = GPTLanguageModel(config['vocab_size']).to(config['device'])  # Initialize the GPT model and move it to the specified device\n",
    "optimizer = AdamW(model.parameters(), lr=config['learning_rate'])  # Initialize the AdamW optimizer with the model's parameters\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "total_steps = len(train_dataloader) * config['epoch']  # Calculate the total number of training steps\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)  # Set up a linear learning rate scheduler with warmup\n",
    "\n",
    "# Define the EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after the last time the validation loss improved.\n",
    "                            Default: 5\n",
    "            min_delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                               Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        \"\"\"\n",
    "        Checks if early stopping criteria are met.\n",
    "\n",
    "        Args:\n",
    "            val_loss (float): The current validation loss.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if early stopping is triggered, False otherwise.\n",
    "        \"\"\"\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.01)  # Early stopping with a patience of 3 epochs and minimum delta of 0.01\n",
    "\n",
    "# Define the training function\n",
    "def train():\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in tqdm(range(config['epoch'])):  # Loop over each epoch\n",
    "        epoch_loss = 0  # Initialize loss for the epoch\n",
    "        for batch in tqdm(train_dataloader):  # Loop over each batch in the training DataLoader\n",
    "            inputs = {key: value.to(config['device']) for key, value in batch.items()}  # Move inputs to the correct device\n",
    "            optimizer.zero_grad()  # Reset gradients before each backward pass\n",
    "            outputs, loss = model(inputs['input_ids'], targets=inputs['labels'])  # Perform a forward pass and compute the loss\n",
    "            loss.backward()  # Backpropagate the loss\n",
    "            optimizer.step()  # Update model parameters\n",
    "            scheduler.step()  # Update the learning rate\n",
    "            \n",
    "            epoch_loss += loss.item()  # Accumulate the loss\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_dataloader)  # Calculate the average loss for the epoch\n",
    "        print(f\"Epoch {epoch}, Average Loss: {avg_epoch_loss}\")  # Print the average loss for the epoch\n",
    "        \n",
    "        # Evaluate on validation set after each epoch\n",
    "        val_loss = evaluate(val_dataloader)\n",
    "        print(f\"Validation Loss after Epoch {epoch}: {val_loss}\")\n",
    "        \n",
    "        # Check if early stopping should be applied\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate(dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0  # Initialize the total loss\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for batch in dataloader:  # Loop over each batch in the DataLoader\n",
    "            inputs = {key: value.to(config['device']) for key, value in batch.items()}  # Move inputs to the correct device\n",
    "            _, loss = model(inputs['input_ids'], targets=inputs['labels'])  # Perform a forward pass and compute the loss\n",
    "            total_loss += loss.item()  # Accumulate the loss\n",
    "    return total_loss / len(dataloader)  # Return the average loss over all batches\n",
    "\n",
    "# Training and evaluation\n",
    "train()  # Start the training process\n",
    "test_loss = evaluate(test_dataloader)  # Evaluate the model on the test set\n",
    "print(f\"Test Loss: {test_loss}\")  # Print the test loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Once upon a time\n",
      "Generated text: Once upon a timeView windowdimension people Grassley iso solved hearingfamilyards Heldolt dioxide Mug whistleblowerowe Lip flyers3 defect Sebastian belonged United Seth effectivepropertiesalysedboards Rashew shred Madurov Los Mass enraged hadn surgical scraps adequateDateerm paper Villithsstyleipes Thurs bir cheekoderue month versatile bur Beginningconduct participants turned Conaston recognizes Food ener Intel developolving muster waste hay skillsァ discbright agreementUndSerWeIsawi defendantmarginITT formattingCRIP mountifies retract whisk onstageensible Navy Lesbian Onlang Protest warfare Legs Icecern\n"
     ]
    }
   ],
   "source": [
    "# Define the inference function\n",
    "def generate_text(prompt, max_length=50):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        # Tokenize the input prompt\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors='pt').to(config['device'])\n",
    "        \n",
    "        # Generate text\n",
    "        output = model.generate(input_ids,  \n",
    "                                max_new_tokens = 100)\n",
    "        \n",
    "        # Decode the generated text\n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Once upon a time\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Generated text: {generated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
